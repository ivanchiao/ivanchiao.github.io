<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="斜光的个人主页">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="斜光的个人主页">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Zhao Chen">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>斜光的个人主页</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">斜光的个人主页</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/15/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhao Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="斜光的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/15/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/" class="post-title-link" itemprop="url">feature selection</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-07-15 21:51:57 / Modified: 21:51:49" itemprop="dateCreated datePublished" datetime="2021-07-15T21:51:57+08:00">2021-07-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-Dimensionality-reduction-降维"><a href="#1-Dimensionality-reduction-降维" class="headerlink" title="1. Dimensionality reduction (降维)"></a>1. Dimensionality reduction (降维)</h2><p><strong>Dimensionality reduction是数据挖掘/机器学习里面用来移除不相关特征(irrelevant, noisy)、冗余特征(redundant)的一种常用技术。</strong>所谓的不相关特征(irrelevant, noisy)，也就是说这些特征和你要做的事情没有半毛钱关系。举个例子，如果你的算法是为了预测一个上海某高校本科生毕业年薪是多少，但是你采集变量的时候采集了格陵兰岛今年的降水量。降水量这个特征可以说是没有半毛钱关系；所谓的冗余特征(redundant)，也就是说你采集的特征里面有可能高度相关的：比如说上一届学长学姐的平均税前收入、平均税后收入、平均纳税数额。</p>
<p>那么同学们有可能会问：数据不是越多越好吗？我们为什么要移除其中一部分变量呢？其实主要有两个原因：1) 由于curse of dimensionality的存在（维数诅咒），导致很多在较低维度空间有效的算法，到了高维空间就可能无效了。2）由于时间和金钱成本，如果你的数据过于庞大，那么用来运行算法的时间以及储存数据的成本就会大大增加。对于大公司来说，金钱都不是太大问题；更多的时候，他们考虑的是时间成本。因为很多时候，他们都希望自己的算法能够提供实时决策(real-time decision)。</p>
<p><strong>Dimensionality reduction可以粗略地分为两类</strong></p>
<ul>
<li>Feature extraction/Feature projection(特征提取/特征投影)</li>
<li>Feature selection(特征选择)。</li>
</ul>
<h2 id="2-Feature-extraction-Feature-projection-特征提取-特征投影"><a href="#2-Feature-extraction-Feature-projection-特征提取-特征投影" class="headerlink" title="2. Feature extraction/ Feature projection(特征提取/特征投影)"></a>2. Feature extraction/ Feature projection(特征提取/特征投影)</h2><p><strong>Feature extraction/ Feature projection</strong>这一类方法将高维的特征空间投影到一个新的低维特征空间，这些新构造的低维空间里面的feature往往都是original feature（原始特征）的组合（线性组合，加权组合等）。我们可以看到，这一类技术并不保留original feature，所以使用这类降维技术的算法解释性(interpretability)都相对较差，从而相比之下feature selection有的时候更受欢迎。这一类技术的代表主要有： 主成分分析(Principle Component Analysis)、线性判别分析(Linear Discriminant Analysis)、典型相关分析(Canonical Correlation Analysis). 再说点题外话：<strong>对于这一类技术，我更喜欢叫它feature projection(特征投影)</strong>，这是为什么呢？因为feature extraction这个词汇在机器学习领域有不同的含义，比如说在时间序列分析里面，当我们讲feature extraction时，我们一般是指从一段时间序列里面提取(extract)出一些有用特征 (feature)，比如说此时间序列的max、min、mean、std、kurtosis、skewness等等。还有的部分文献会叫这种方法feature transformation(特征转换)，其实这也是不恰当的。因为在机器学习领域，当我们说feature transformation的时候，一般是指对一个变量进行函数变换，比如说x变到log(x)等等。</p>
<h2 id="3-Feature-selection-特征选择"><a href="#3-Feature-selection-特征选择" class="headerlink" title="3. Feature selection(特征选择)"></a>3. Feature selection(特征选择)</h2><p><strong>Feature selection</strong> 这一类方法从原始特征(original feature)空间里面选择出一部分feature出来，我们希望这部分feature里面包括最少的不相关特征(irrelevant, noisy feature)和冗余特征(redundant)。我们可以看到，这类方法会保留原始特征，所以使用这类降维技术的算法解释性(interpretability)都相对较好，这也是为什么我在我的项目里面选择使用feature selection的原因。这一类技术的代表主要有：    Information Gain、Relief、Fisher Score、Lasso等。</p>
<h2 id="4-Feature-selection-展开描述"><a href="#4-Feature-selection-展开描述" class="headerlink" title="4. Feature selection 展开描述"></a>4. Feature selection 展开描述</h2><p>鉴于很多同学或者参考文献一开始就讲Filter、Wrapper、Embedding各种分类方法，我认为在讲这些分类方法之前，我们首先需要考虑以下几件事：</p>
<p>1）我们的算法是属于哪一类？</p>
<ul>
<li>Supervised(classification、regression)、</li>
<li>unsupervised(clustering)、</li>
<li>semi-supervised. </li>
</ul>
<p>2)  我们的特征空间属于哪一类：</p>
<ul>
<li>Flat features (也就是我们最常见的Dataset的情况，特征是静态的、而且彼此之间不存在特定的组织架构关系，结合后面两点对比来看就能理解); </li>
<li>Structured Features（特征之间存在一定的组织架构关系），比如说 Group Structure（某些特征属于特定小组，若选则全都选、若不选则全都不要） 、Tree Structure （特征之间存在父子包含关系，若父特征被选中，则所有的子特征都会被选中）</li>
<li>Streaming features （随着时间的变动，会采集新的特征）</li>
</ul>
<p>3）最后才是考虑你喜欢哪一种Feature Selection方法：</p>
<ul>
<li><strong>Filter方法: 这类方法将从Dataset的feature本身出发，考察变量之间的相关性(correlation)等，并不考虑做了feature selection之后你使用的特定算法</strong>。举个例子：如果说数据是有label的(我们的算法是classification)，并且我们的特征空间是flat feature，那么它可能会计算label和其它feature之间的相关性来找到relevant features; 然后再考察relevant features之间的相关性，来找到redundant features. 如果我们的数据是没有label(我们的算法是clustering)那么可能直接计算features之间的相关性，或者使用其它方法。这类方法其实是最基本的，但是在国内的统计学教科书上很少做相关介绍。比如说，我们可以使用Fisher score,    Mutual Information , Relief 等来衡量上述的correlation. </li>
<li><strong>Wrapper方法：这类方法在做feature selection的时候，先选出来一部分特征，然后将这部分特征用于运行你的特定算法（比如说决策树），看看表现如何；然后重复上述步骤，直到选出“最好的”特征子集为止。</strong></li>
<li><strong>Embedding 方法：这一类方法的话，就是把feature selection这种思想在算法里built-in了，并不单独拎出来。</strong>举个例子：见下图，就lasso回归来说，在拟合误差项后面再给你整一项惩罚项来进行feature selection。</li>
</ul>
<script type="math/tex; mode=display">
\sum_{i=1}^M(y_i-\hat{y_i})^2 = \sum_{i=1}^M (y_i - \sum_{j=0}^pw_j \times x_{ij}) + \lambda \sum_{j=0}^p|w_j|</script><p>我们可以看到这就是built-in的思想，你无法将其单拎出来，而是“浑然天成“一体。再说一点题外话，在实际应用中，如果feature dimension过于庞大，一般都是使用filter方法；或者是使用filter方法进行预处理，剔除一批“劣质”特征，然后再使用Wrapper或者Embedding进行“精选”。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/03/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%B9%B3%E6%BB%91CTR%E7%89%B9%E5%BE%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhao Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="斜光的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/03/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%B9%B3%E6%BB%91CTR%E7%89%B9%E5%BE%81/" class="post-title-link" itemprop="url">CTR预估中的贝叶斯平滑方法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-03 12:28:58" itemprop="dateCreated datePublished" datetime="2021-07-03T12:28:58+08:00">2021-07-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-07-15 21:54:30" itemprop="dateModified" datetime="2021-07-15T21:54:30+08:00">2021-07-15</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-Challenges"><a href="#1-Challenges" class="headerlink" title="1. Challenges"></a>1. Challenges</h2><p>由于数据的稀疏性，对广告进行CTR预估是比较具有挑战性的，预估出来的CTR的可靠性不高，且具有较大的方差。</p>
<p>1）当广告的展示次数较少的时候，对其直接进行CTR的统计计算会导致一个偏高的结果。比如某个广告只展示了1次，被点击了1次，则纯粹的统计CTR=1.0，这显然是过分高估了。</p>
<p>2）当广告的展示次数很大，但点击次数很少或几乎没有的时候，对其直接进行CTR的统计计算会导致一个偏低的结果。比如某个广告没有被点击过，则纯粹的统计CTR=0.0，这显然是过分低估了。</p>
<h2 id="2-Motivation"><a href="#2-Motivation" class="headerlink" title="2. Motivation"></a>2. Motivation</h2><p>在许多场景下，数据是很自然地存在层级结构，或者可以通过数据的聚类的方式得到层级结构的。</p>
<p><img src="https://i.loli.net/2021/07/03/oxVKB3AXPwqNLRT.png" alt="img"></p>
<p>我们假设事件的发生并不是相互独立的，相反，在层级结构中相对比较靠近的两个事件的相关性要大于距离较远的两个事件，它们之间拥有很多共通之处。于是，我们便可以利用“相似”事件的信息来丰富某个我们感兴趣的事件（这个事件本事的发生的次数比较少）。具体到我们现有的场景下，可以利用与我们需要预估的事件（比如query-ad pair，或者page-ad pair）的“相似”事件的信息来帮助我们来做出预估计算。</p>
<p>假设有相同account 下的N个ad $(a_1, a_2, …, a_N)$ ，以及所在的page，我们感兴趣的是page-ad pair的CTR，于是我们可以利用贝叶斯的方法来结合（1）这个ad本身的信息，以及（2）该page下与这个ad来自相同account的其它ad的信息。我们观测到的点击信息为 $(C_1, C_2, …,C_N)$ ，这些点击信息源自各个ad的潜在的CTR信息 $(r_1, r_2,…,r_N)$ 有关，点击信息服从二项分布 $Binomial (I_i, r_i)$ 。那么潜在的每个 ad的CTR，可以看作是来自于它们相同的account的公有信息，其服从 $Beta(\alpha, \beta)$。于是乎，每个ad的隐含CTR值，不仅与观测到的展示点击数据 $(I_i, C_i)$ 有关，还与其所属的account的整体信息有关，即与 $\alpha, \beta$ 这对超参数有关。我们可以利用二项分布和贝塔分布的共轭特性，计算所有ad所属的相同account的似然函数，然后利用最大似然估计（MLE）来计算超参数</p>
<p>我们观测到的点击信息为 $(C_1, C_2, …,C_N)$ ，这些点击信息源自各个ad的潜在的CTR信息 $(r_1, r_2,…,r_N)$，点击信息服从二项分布 $Binomial (I_i, C_i)$ 有关，还与其所属的account的整体信息有关，即与 $\alpha, \beta$ 这对超参数有关。我们可以利用二项分布和贝塔分布的共轭特性，计算所有ad所属的相同account的似然函数，然后利用最大似然估计（MLE）来计算超参数  $\alpha, \beta$ ，当有了   $\alpha, \beta$ 的估计值 $\hat{\alpha}, \hat{\beta}$后，我们便可以得到每个ad的后验估计：$\hat{r}_i=(C_i+\hat{\alpha}) / (I_i + \hat{\alpha} + \hat{\beta})$ 。这个后验估计值可以作为一个平滑后的CTR值，它要比单纯地统计CTR $C_i / I_i$ 拥有更小的方差，更加稳定。</p>
<h3 id="3-数据连续性"><a href="#3-数据连续性" class="headerlink" title="3. 数据连续性"></a>3. 数据连续性</h3><p>在很多场景下，我们更关心CTR的趋势，而不是一个特定时间点的CTR值。因为对于展示量较少的page-ad pair，某个特定时间点的CTR预估值是包含很大噪声的。我们将展现和点击看做是离散集合的重复观测值，然后使用<strong>指数平滑技术</strong>进行CTR平滑。假设对于page-ad pair，我们有M天的展现 $(I_1, I_2, …, I_M)$ 和 点击 $(C_1, C_2, …, C_M)$ ，然后我们希望预估出第M天的CTR。我们将平滑后的展现和点击记为 $\hat{I}, \hat{C}$ ，它们可由下面公式得到（这里只给出了点击的公式计算，展现也同理）：</p>
<p><img src="https://i.loli.net/2021/07/03/tfG8YLeO29cXlR6.png" alt="image-20210703214904575" style="zoom:50%;" /></p>
<p>其中 $0 &lt; \gamma &lt; 1$ 是平滑系数，它控制着我们把历史信息纳入我们平滑的计算中的权重大小。</p>
<p><strong>上述的两种方法：（1）数据层级结构的贝叶斯平滑，（2）时间窗口的指数平滑，可以结合使用。</strong></p>
<h3 id="4-数据层级结构的贝叶斯平滑方法具体介绍"><a href="#4-数据层级结构的贝叶斯平滑方法具体介绍" class="headerlink" title="4. 数据层级结构的贝叶斯平滑方法具体介绍"></a>4. 数据层级结构的贝叶斯平滑方法具体介绍</h3><p>这里我们规定将page-ad pair的信息在层级结构上上升到publisher-account pair的信息（不同page隶属于相同的publisher，不同的ad隶属于相同的account）。</p>
<p>有两个假设：</p>
<p>（1）对于publisher-account pair，有1个隐含的CTR概率分布，而每个page-ad pair的CTR可以看作是从这个整体的CTR分布中随机采样出来的。</p>
<p><img src="https://i.loli.net/2021/07/03/3fAkjzF21BpCnR9.png" alt="image-20210703215048477" style="zoom:50%;" /></p>
<p>（2）对于page-ad pair，我们观测到其对应的展现信息和点击信息。</p>
<p><img src="https://i.loli.net/2021/07/03/Qy5o7mz4TWMRwPJ.png" alt="image-20210703215118397" style="zoom:50%;" /></p>
<p>其对应的概率图模型如下，灰色部分是观测变量，白色部分是隐含变量：</p>
<p><img src="https://i.loli.net/2021/07/03/2ysV8OmjavSczw7.png" alt="image-20210703215355904" style="zoom:50%;" /></p>
<p>对于该publisher-account下的所有page-ad pair的点击计算出似然函数：</p>
<p><img src="https://i.loli.net/2021/07/03/rgUmH5fLqAjZnsp.png" alt="image-20210703215416279" style="zoom:50%;" /></p>
<p>将上述的log似然函数分别对α和β求导数，即为：</p>
<p><img src="https://i.loli.net/2021/07/03/Nohtd8jfMx3KvwY.png" alt="image-20210703215438290" style="zoom:50%;" /></p>
<p>通过fixed-point iteration方法，我们可以得到α和β在每一轮迭代中的更新公式：</p>
<p><img src="https://i.loli.net/2021/07/15/vz4lIUGXpLiV9g8.png" alt="image-20210703215514582" style="zoom:50%;" /></p>
<p>迭代的终止条件为一个固定的迭代次数（如1000次），或者α和β在一次迭代中的变化值都小于一个epsilon（如1E-10）。一旦有了 $\hat{\alpha}, \hat{\beta}$ 我们便可以得到每个ad的后验估计：$\hat{r}_i=(C_i+\hat{\alpha}) / (I_i + \hat{\alpha} + \hat{\beta})$</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/01/%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhao Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="斜光的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/01/%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1/" class="post-title-link" itemprop="url">样本不均衡问题</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-07-01 16:32:45 / Modified: 16:55:10" itemprop="dateCreated datePublished" datetime="2021-07-01T16:32:45+08:00">2021-07-01</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-为什么类别不平衡会影响模型输出？"><a href="#1-为什么类别不平衡会影响模型输出？" class="headerlink" title="1. 为什么类别不平衡会影响模型输出？"></a>1. 为什么类别不平衡会影响模型输出？</h3><p>大部分模型的默认阈值为输出值的中位数。比如逻辑回归的输出范围为[0,1]，当某个样本的输出大于0.5就会被划分为正例，反之为反例。在数据的类别不平衡时，采用默认的分类阈值可能会导致输出全部为反例，产生虚假的高准确度，导致分类失败。<strong>因此很多答主提到了几点：1. 可以选择调整阈值，使得模型对于较少的类别更为敏感</strong>  <strong>2. 选择合适的评估标准，比如ROC或者F1，而不是准确度（accuracy）</strong>。举个简单的例子，Sklearn的决策树有一个参数是class_weight，就是用来调整分类阈值的，文档中的公式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n_samples / (n_classes * np.bincount(y)) </span><br></pre></td></tr></table></figure>
<p>所以遇到不平衡数据，用<strong>集成学习+阈值调整可以作为第一步尝试。</strong></p>
<h3 id="2-采样法和类别不平衡有什么关系？"><a href="#2-采样法和类别不平衡有什么关系？" class="headerlink" title="2. 采样法和类别不平衡有什么关系？"></a>2. 采样法和类别不平衡有什么关系？</h3><p><strong>而通过采样（sampling）来调整数据的不平衡，是另一种解决途径，并且可以和阈值调整同时使用</strong>。但采样法不是单纯的从数据角度改变了模型阈值，还改变了模型优化收敛等一系列过程，在此不赘述。</p>
<p><strong>而采样法最受人诟病的就是可能会改变原始数据的分布，从而带来偏差</strong>。这个说法是否正确呢？让我们带着疑问来分析一下不同的采样方法有什么区别，该怎么使用。<strong>有鉴于总被人批评答题公式太多，今天就以可视化和实验为主</strong>。</p>
<h3 id="3-如何直观理解采样法？"><a href="#3-如何直观理解采样法？" class="headerlink" title="3. 如何直观理解采样法？"></a>3. 如何直观理解采样法？</h3><p>Cardio 数据集，1831条数据，每条数据有21个特征。其中正例176个（9.6122%），反例1655个（90.3878%），属于典型的类别不平衡问题。</p>
<p>因为原始数据是21维不易展示，所以我们使用T-SNE把数据嵌入到2维空间。图中红色代表正例，蓝色代表反例数据重叠会加深颜色，甚至造成颜色混合。左上、左下、右上和右下依次是：</p>
<ul>
<li>原始数据（Original）：未经过任何采样处理</li>
<li>欠采样（Undersampling）：从反例中随机选择176个数据，与正例合并</li>
<li>过采样（Oversampling）：从正例中反复抽取并生成1655个数据（势必会重复），并与反例合并</li>
<li>SMOTE：也是一种过采样方法。SMOTE通过找到正例中数据的近邻，来合成新的1655-176=1479个 “新正例”，并与原始数据合并。此处应注意SMOTE并不是简单的重复，而是一种基于原始数据的生成。另外一个相似的算法是ADASYN</li>
</ul>
<p><img src="https://i.loli.net/2021/07/01/o4tS6uOcqKdPwI8.jpg" alt="preview" style="zoom: 67%;" /></p>
<ul>
<li><strong>过采样（右上）只是单纯的重复了正例</strong>，因此会过分强调已有的正例。如果其中部分点标记错误或者是噪音，那么错误也容易被成倍的放大。<strong>因此最大的风险就是对正例过拟合</strong>。</li>
<li><strong>欠采样（左下）抛弃了大部分反例数据</strong>，从而弱化了中间部分反例的影响，<strong>可能会造成偏差很大的模型</strong>。当然，如果数据不平衡但两个类别基数都很大，或许影响不大。同时，<strong>数据总是宝贵的，抛弃数据是很奢侈的</strong>，因此另一种常见的做法是反复做欠采样，生成 1655/176 ≈ 9 个新的子样本。其中每个样本的正例都使用这176个数据，而反例则从1655个数据中不重复采样。最终对这9个样本分别训练，并集成结果。这样数据达到了有效利用，但也存在风险：<ul>
<li><strong>训练多个模型造成了过大的开销</strong>，合并模型结果需要额外步骤，有可能造成其他错误</li>
<li><strong>正例被反复使用，和过采样一样，很容易造成模型的过拟合</strong></li>
</ul>
</li>
<li>SMOTE（右下）可以看出和过采样（右上）有了明显的不同，因为不单纯是重复正例了，而是在局部区域通过K-近邻生成了新的正例。相较于简单的过采样， SMOTE：<ul>
<li>降低了过拟合风险。K近邻在局部合成数据可以被理解为一种集成学习，降低了方差。但或许也错误的加强了局部的偶然性，从而增加了过拟合风险。</li>
<li>也可以理解为一种过采样的soft version，对于噪音的抵抗性更强</li>
<li>缺点也有，比如运算开销加大，同时可能会生成一些“可疑的点”，如下图所示</li>
</ul>
</li>
</ul>
<p><img src="https://i.loli.net/2021/07/01/Y3lAcUzsvJDfoR8.jpg" alt="preview"></p>
<h3 id="4-采样法归纳总结"><a href="#4-采样法归纳总结" class="headerlink" title="4. 采样法归纳总结"></a>4. 采样法归纳总结</h3><p>让我们把实验所中归纳出的经验性性质总结一下，实验细节和结果在文末：</p>
<ul>
<li>采样方法一般比直接调整阈值的效果要好。</li>
<li>使用采样方法（过采样和欠采样）一般可以提升模型的泛化能力，但有一定的过拟合的风险，应搭配使用正则化模型</li>
<li>过采样的结果较为稳定，作为一种升级版的过采样，SMOTE也是不错的处理方式，大部分时候和过采样的效果相似</li>
<li>过采样大部分时候比欠采样的效果好，但很难一概而论哪种方法最好，还是需要根据数据的特性（如分布）具体讨论</li>
<li>实验结果在（L2正则的逻辑回归、随机森林、xgboost）一致，因此和采样法搭配使用的模型最好可以很好的处理过拟合</li>
</ul>
<p>但是不是过采样就是万能药？未必。首先，它不可避免的带来更大的运算开销，其次当数据中噪音过大时，结果反而可能会更差因为噪音也被重复使用。当然，除此以外还有更严谨的统计学理论说明采样的力量，以及如何正确采样，此处按下不表。我的一个不成熟的经验是：<strong>使用过采样（或SMOTE）+强正则模型（如XGBoost）可能比较适合不平衡的数据。</strong>拿到一个新的数据时，可以不妨直接先试试这个方法，作为基准（Baseline）。</p>
<p>多说两句的话，很多方法都可以结合起来，比如过采样和欠采样是可以结合起来的。一个比较成熟的算法就是用SMOTE过采样，再利用Tomek’s link再控制新的样本空间。有兴趣的朋友可以移步<a href="https://link.zhihu.com/?target=http%3A//contrib.scikit-learn.org/imbalanced-learn/stable/combine.html">4. Combination of over- and under-sampling</a>，这个例子的作者开发了imbalanced-learn（<a href="https://link.zhihu.com/?target=http%3A//contrib.scikit-learn.org/imbalanced-learn/stable/index.html">Welcome to imbalanced-learn documentation!</a>），是一个Python上处理数据不平衡的工具库，这个答案中的实验代码都是基于这个工具库。</p>
<p>Cardio数据集：<a href="https://link.zhihu.com/?target=http%3A//odds.cs.stonybrook.edu/cardiotocogrpahy-dataset/">Cardiotocogrpahy dataset</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Data: cardio | shape: (<span class="number">1831</span>, <span class="number">21</span>) | F1</span><br><span class="line">Threshold Moving:       <span class="number">0.829987896832</span></span><br><span class="line">Original:               <span class="number">0.805920420913</span></span><br><span class="line">Oversampling:           <span class="number">0.963759891658</span></span><br><span class="line">Undersampling:          <span class="number">0.938725868726</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.821234363304</span></span><br><span class="line">SMOTE:                  <span class="number">0.971714100029</span></span><br><span class="line"></span><br><span class="line">Data: cardio | shape: (<span class="number">1831</span>, <span class="number">21</span>) | ROC</span><br><span class="line">Threshold Moving:       <span class="number">0.992879432167</span></span><br><span class="line">Original:               <span class="number">0.991171853188</span></span><br><span class="line">Oversampling:           <span class="number">0.992246339935</span></span><br><span class="line">Undersampling:          <span class="number">0.992405698663</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.992896183665</span></span><br><span class="line">SMOTE:                  <span class="number">0.993895382919</span></span><br></pre></td></tr></table></figure>
<p>Letter数据集：<a href="https://link.zhihu.com/?target=http%3A//odds.cs.stonybrook.edu/letter-recognition-dataset/">Letter Recognition dataset</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Data: letter | shape: (<span class="number">1600</span>, <span class="number">32</span>) | F1</span><br><span class="line">Threshold Moving:       <span class="number">0.257964355223</span></span><br><span class="line">Original:               <span class="number">0.2322000222</span></span><br><span class="line">Oversampling:           <span class="number">0.80419404639</span></span><br><span class="line">Undersampling:          <span class="number">0.762522610875</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.265496694535</span></span><br><span class="line">SMOTE:                  <span class="number">0.94066718832</span></span><br><span class="line"></span><br><span class="line">Data: letter | shape: (<span class="number">1600</span>, <span class="number">32</span>) | ROC</span><br><span class="line">Threshold Moving:       <span class="number">0.778733333333</span></span><br><span class="line">Original:               <span class="number">0.775133333333</span></span><br><span class="line">Oversampling:           <span class="number">0.853071111111</span></span><br><span class="line">Undersampling:          <span class="number">0.798</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.7762</span></span><br><span class="line">SMOTE:                  <span class="number">0.961724444444</span></span><br></pre></td></tr></table></figure>
<p>Mnist数据集：<a href="https://link.zhihu.com/?target=http%3A//odds.cs.stonybrook.edu/mnist-dataset/">mnist dataset - ODDS</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Data: mnist | shape: (<span class="number">7603</span>, <span class="number">100</span>) | F1</span><br><span class="line">Threshold Moving:       <span class="number">0.809942609314</span></span><br><span class="line">Original:               <span class="number">0.843460421197</span></span><br><span class="line">Oversampling:           <span class="number">0.963745254804</span></span><br><span class="line">Undersampling:          <span class="number">0.939662842407</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.795183545913</span></span><br><span class="line">SMOTE:                  <span class="number">0.972652248517</span></span><br><span class="line"></span><br><span class="line">Data: mnist | shape: (<span class="number">7603</span>, <span class="number">100</span>) | ROC</span><br><span class="line">Threshold Moving:       <span class="number">0.985425233631</span></span><br><span class="line">Original:               <span class="number">0.985211857272</span></span><br><span class="line">Oversampling:           <span class="number">0.991881775625</span></span><br><span class="line">Undersampling:          <span class="number">0.976346938776</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.977791067047</span></span><br><span class="line">SMOTE:                  <span class="number">0.99455044033</span></span><br></pre></td></tr></table></figure>
<p>Ionosphere数据集：<a href="https://link.zhihu.com/?target=http%3A//odds.cs.stonybrook.edu/ionosphere-dataset/">Ionosphere dataset</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Data: ionosphere | shape: (<span class="number">351</span>, <span class="number">33</span>) | F1</span><br><span class="line">Threshold Moving:       <span class="number">0.755263843708</span></span><br><span class="line">Original:               <span class="number">0.77205596336</span></span><br><span class="line">Oversampling:           <span class="number">0.858191681928</span></span><br><span class="line">Undersampling:          <span class="number">0.787040254432</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.757907605743</span></span><br><span class="line">SMOTE:                  <span class="number">0.849245387823</span></span><br><span class="line"></span><br><span class="line">Data: ionosphere | shape: (<span class="number">351</span>, <span class="number">33</span>) | ROC</span><br><span class="line">Threshold Moving:       <span class="number">0.8816344887</span></span><br><span class="line">Original:               <span class="number">0.88384133982</span></span><br><span class="line">Oversampling:           <span class="number">0.946363011452</span></span><br><span class="line">Undersampling:          <span class="number">0.881254109139</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.87103349549</span></span><br><span class="line">SMOTE:                  <span class="number">0.953137058851</span></span><br></pre></td></tr></table></figure>
<p>Pima数据集：<a href="https://link.zhihu.com/?target=http%3A//odds.cs.stonybrook.edu/pima-indians-diabetes-dataset/">Pima Indians Diabetes dataset</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Data: pima | shape: (<span class="number">768</span>, <span class="number">8</span>) | F1</span><br><span class="line">Threshold Moving:       <span class="number">0.684815686152</span></span><br><span class="line">Original:               <span class="number">0.614437063812</span></span><br><span class="line">Oversampling:           <span class="number">0.744106797407</span></span><br><span class="line">Undersampling:          <span class="number">0.762079698321</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.667769584397</span></span><br><span class="line">SMOTE:                  <span class="number">0.749990784595</span></span><br><span class="line"></span><br><span class="line">Data: pima | shape: (<span class="number">768</span>, <span class="number">8</span>) | ROC</span><br><span class="line">Threshold Moving:       <span class="number">0.824891737892</span></span><br><span class="line">Original:               <span class="number">0.824757834758</span></span><br><span class="line">Oversampling:           <span class="number">0.83276</span></span><br><span class="line">Undersampling:          <span class="number">0.825577308626</span></span><br><span class="line">Undersampling Ensemble: <span class="number">0.82011965812</span></span><br><span class="line">SMOTE:                  <span class="number">0.84188</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/07/01/%E5%BC%82%E5%B8%B8%E5%80%BC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhao Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="斜光的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/01/%E5%BC%82%E5%B8%B8%E5%80%BC%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/" class="post-title-link" itemprop="url">异常值检测算法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-07-01 10:29:29 / Modified: 10:54:57" itemprop="dateCreated datePublished" datetime="2021-07-01T10:29:29+08:00">2021-07-01</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="1-数字异常值-Numeric-Outlier"><a href="#1-数字异常值-Numeric-Outlier" class="headerlink" title="1. 数字异常值 ( Numeric Outlier )"></a>1. 数字异常值 ( Numeric Outlier )</h3><p><strong>均方差</strong></p>
<p>在统计学中，如果一个数据分布近似正态，那么大约 68% 的数据值会在均值的一个标准差范围内，大约 95% 会在两个标准差范围内，大约 99.7% 会在三个标准差范围内。因此，如果你有任何数据点超过标准差的 3 倍，那么这些点很有可能是异常值或离群点。</p>
<p><img src="https://i.loli.net/2021/07/01/3wkjlsuSxcf51RL.png" alt="image-20210701103314459" style="zoom: 33%;" /></p>
<p><strong>箱型图</strong></p>
<p>箱形图可以用来观察数据整体的分布情况，利用中位数，25/%分位数，75/%分位数，上边界，下边界等统计量来来描述数据的整体分布情况。通过计算这些统计量，生成一个箱体图，箱体包含了大部分的正常数据，而在箱体上边界和下边界之外的，就是异常数据。</p>
<p>其中上下边界的计算公式如下：</p>
<p>UpperLimit=Q3+1.5IQR=75%分位数+（75%分位数-25%分位数）*1.5，</p>
<p>LowerLimit=Q1－1.5IQR=25%分位数-（75%分位数-25%分位数）*1.5</p>
<p>（将数据由小到大排序，处于中间的为中位数，即50%分位数，在75%位置的即为75%分位数或四分之三分位数——Q3，在25%位置的即为25%分位数或四分之一分位数——Q1）</p>
<p>参数说明：</p>
<ol>
<li><p>Q1表示下四分位数，即25%分位数；Q3为上四分位数，即75%分位数；IQR表示上下四分位差，系数1.5是一种经过大量分析和经验积累起来的标准，一般情况下不做调整。</p>
</li>
<li><p>分位数的参数可根据具体预警结果调整：25%和75%，是比较灵敏的条件，在这种条件下，多达25%的数据可以变得任意远而不会很大地扰动四分位。具体业务中可结合拟合结果自行调整为其他分位。</p>
</li>
</ol>
<p><img src="https://i.loli.net/2021/07/01/y13b7Ou4KchseSF.png" alt="preview"></p>
<h3 id="2-Z-score"><a href="#2-Z-score" class="headerlink" title="2. Z-score"></a>2. Z-score</h3><p>Z-score是一维或低维特征空间中的参数异常检测方法。该技术假定数据是高斯分布，异常值是分布尾部的数据点，因此远离数据的平均值。距离的远近取决于使用公式计算的归一化数据点 $Z_i$ 的设定阈值 Zthr：</p>
<script type="math/tex; mode=display">
Z_i = \frac{X_i-\mu}{\sigma}</script><p>然后经过标准化处理后，异常值也进行标准化处理，其绝对值大于Zthr：</p>
<script type="math/tex; mode=display">
|Z_i| > Z_{thr}</script><p>Zthr值一般设置为2.5、3.0和3.5。</p>
<h3 id="3-DBSCAN"><a href="#3-DBSCAN" class="headerlink" title="3. DBSCAN"></a>3. DBSCAN</h3><p>该技术基于 DBSCAN聚类方法，DBSCAN是一维或多维特征空间中的非参数，基于密度的离群值检测方法。</p>
<p>在DBSCAN聚类技术中，所有数据点都被定义为核心点（Core Points）、边界点（Border Points）或噪声点（Noise Points）。</p>
<ul>
<li>核心点是在距离ℇ内至少具有最小包含点数（minPTs）的数据点；</li>
<li>边界点是核心点的距离ℇ内邻近点，但包含的点数小于最小包含点数（minPTs）；</li>
<li>所有的其他数据点都是噪声点，也被标识为异常值；</li>
</ul>
<p>从而，异常检测取决于所要求的最小包含点数、距离ℇ和所选择的距离度量，比如欧几里得或曼哈顿距离。</p>
<h3 id="4-孤立森林-Isolation-Forest"><a href="#4-孤立森林-Isolation-Forest" class="headerlink" title="4. 孤立森林 ( Isolation Forest )"></a>4. 孤立森林 ( Isolation Forest )</h3><p>该方法是一维或多维特征空间中大数据集的非参数方法，其中的一个重要概念是孤立数。</p>
<p>孤立数是孤立数据点所需的拆分数。通过以下步骤确定此分割数：</p>
<ul>
<li>随机选择要分离的点“a”；</li>
<li>选择在最小值和最大值之间的随机数据点“b”，并且与“a”不同；</li>
<li>如果“b”的值低于“a”的值，则“b”的值变为新的下限；</li>
<li>如果“b”的值大于“a”的值，则“b”的值变为新的上限；</li>
<li>只要在上限和下限之间存在除“a”之外的数据点，就重复该过程；</li>
</ul>
<p>与孤立非异常值相比，它需要更少的分裂来孤立异常值，即异常值与非异常点相比具有更低的孤立数。因此，如果数据点的孤立数低于阈值，则将数据点定义为异常值。</p>
<p>阈值是基于数据中异常值的估计百分比来定义的，这是异常值检测算法的起点。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/30/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0(Pearson-Correlation-Coefficient)/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Zhao Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="斜光的个人主页">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/30/%E7%9A%AE%E5%B0%94%E9%80%8A%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0(Pearson-Correlation-Coefficient)/" class="post-title-link" itemprop="url">皮尔逊相关系数(Pearson Correlation Coefficient)</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2021-06-30 11:22:55 / Modified: 11:30:58" itemprop="dateCreated datePublished" datetime="2021-06-30T11:22:55+08:00">2021-06-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>在数据标准化后，Pearson相关性系数、Cosine相似度、欧式距离的平方可认为是等价的</strong>。换句话说，如果你的数据符合正态分布或者经过了标准化处理，那么这三种度量方法输出等价。<strong>对于标准化后的数据求欧氏距离平方并经过简单的线性变化，其实就是Pearson系数</strong></p>
<p>我们一般用欧式距离（向量间的距离）来衡量向量的相似度，但欧式距离无法考虑不同变量间取值的差异。举个例子，变量a取值范围是0至1，而变量b的取值范围是0至10000，计算欧式距离时变量b上微小的差异就会决定运算结果。<strong>而Pearson相关性系数可以看出是升级版的欧氏距离平方，因为它提供了对于变量取值范围不同的处理步骤。因此对不同变量间的取值范围没有要求（unit free），最后得到的相关性所衡量的是趋势。而不同变量量纲上差别在计算过程中去掉了，等价于z-score标准化</strong>。</p>
<p>而未经升级的欧式距离以及cosine相似度，对变量的取值范围是敏感的，在使用前需要进行适当的处理。我个人的经验是，<strong>在低维度可以优先使用标准化后的欧式距离或者其他距离度量</strong>，<strong>在高维度时Pearson相关系数更加适合</strong>。不过说到底，这几个衡量标准差别不大，很多时候的输出结果是非常相似的。</p>
<p><strong>欧氏距离（Euclidean Distance）</strong>是常见的相似性度量方法，可求两个向量间的距离，取值范围为0至正无穷。显然，如果两个向量间的距离较小，那么向量也肯定更为相似。此处需要注意的一点是，欧氏距离计算默认对于每一个维度给予相同的权重，因此如果不同维度的取值范围差别很大，那么结果很容易被某个维度所决定。解决方法除了对数据进行处理以外，还可以使用加权欧氏距离，不同维度使用不同的权重。</p>
<script type="math/tex; mode=display">
d(X_,Y) = \sum_{i=1}^n(X_n-Y_n)^2</script><p><strong>Pearson相关性系数（Pearson Correlation）</strong>是衡量向量相似度的一种方法。输出范围为-1到+1, 0代表无相关性，负值为负相关，正值为正相关。</p>
<script type="math/tex; mode=display">
\rho(X,Y)=\frac{E[(X-\mu_{X})(Y-\mu_{Y})]}{\sigma_X\sigma_Y} =\frac{E[(X-\mu_{X})(Y-\mu_{Y})]}{\sqrt{\sum_{i=1}^{n}{(X_i-\mu_X)^2}}\sqrt{\sum_{i=1}^{n}{(Y_i-\mu_Y)^2}}}</script><p><strong>Cosine相似度也是一种相似性度量</strong>，输出范围和Pearson相关性系数一致，含义也相似。</p>
<script type="math/tex; mode=display">
c(X,Y)=\frac{X\cdot Y}{\left| X \right|\left| Y \right|} =\frac{\sum_{i=1}^{n}{X_iY_i}}{\sqrt{\sum_{i=1}^{n}{X_i^2}}\sqrt{\sum_{i=1}^{n}{Y_i^2}}}</script><p><strong>标准化（Standardization）</strong>是一种常见的数据缩放手段，标准化后的数据均值为0，标准差为1。</p>
<script type="math/tex; mode=display">
z(X) = \frac{X_i-\mu _X}{\sigma_X}</script><p><strong>平方和（Summed Square）与样本方差（Sample Variance）之间的关系</strong></p>
<script type="math/tex; mode=display">
\sigma_X=\sqrt{\frac{\sum_{i=1}^{n}{(X_i-\mu_X)^2}}{n-1}}</script><script type="math/tex; mode=display">
(n-1)\sigma_X^2 = \sum_{i=1}^{n}{(X_i-\mu_X)^2}</script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Zhao Chen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhao Chen</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
